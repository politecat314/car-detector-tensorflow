{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yn5_uV1HLvaz"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "\n",
    "import io\n",
    "import scipy.misc\n",
    "import numpy as np\n",
    "from six import BytesIO\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from six.moves.urllib.request import urlopen\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "import PIL\n",
    "\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "from object_detection.utils import ops as utils_ops\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "tf.get_logger().setLevel('ERROR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IogyryF2lFBL"
   },
   "source": [
    "## Utilities\n",
    "\n",
    "Run the following cell to create some utils that will be needed later:\n",
    "\n",
    "- Helper method to load an image\n",
    "- Map of Model Name to TF Hub handle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "-y9R0Xllefec"
   },
   "outputs": [],
   "source": [
    "def load_image_into_numpy_array(path):\n",
    "    \"\"\"\n",
    "    Load an image from file into a numpy array. Extra dimension added for batching\n",
    "    \"\"\"\n",
    "    with Image.open(path) as image:\n",
    "        (im_width, im_height) = image.size    \n",
    "        image = np.asarray(image)\n",
    "\n",
    "    return image.reshape((1, im_height, im_width, 3)).astype(np.uint8)\n",
    "\n",
    "def getCoordingates(height, width, boxes):\n",
    "    \"\"\"\n",
    "    width: width of the original image\n",
    "    height: height of the original image\n",
    "    boxes: bounding box (np.array)\n",
    "    \n",
    "    returns coordinates of bounding box on acutal image\n",
    "    \"\"\"\n",
    "    upper = height*boxes[0]\n",
    "    left = width*boxes[1]\n",
    "    lower = height*boxes[2]\n",
    "    right = width*boxes[3]\n",
    "    \n",
    "    return upper, left, lower, right\n",
    "\n",
    "def area_of_bounding_box(height, width, boxes):\n",
    "    \"\"\"\n",
    "    width: width of the original image\n",
    "    height: height of the original image\n",
    "    boxes: bounding box (np.array) to calculate the area of\n",
    "    returns the area of bounding box\n",
    "    \"\"\"\n",
    "    upper, left, lower, right = getCoordingates(height, width, boxes)\n",
    "            \n",
    "    area = abs(upper-lower)*abs(left-right)\n",
    "    \n",
    "    return area\n",
    "\n",
    "def image_size(image_np):\n",
    "    \"\"\"\n",
    "    image_np: np.array of image in batch form that goes into model\n",
    "    returns height, width of image given\n",
    "    \"\"\"\n",
    "    \n",
    "    _, height, width, _ = image_np.shape # image dimensions\n",
    "    \n",
    "    return height, width"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NKtD0IeclbL5"
   },
   "source": [
    "## Load label map data (for plotting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5mucYUS6exUJ"
   },
   "outputs": [],
   "source": [
    "PATH_TO_LABELS = './models/research/object_detection/data/mscoco_label_map.pbtxt'\n",
    "category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS, use_display_name=True)\n",
    "\n",
    "label_offsets = {3:\"car\", 6:\"bus\", 8:\"truck\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6917xnUSlp9x"
   },
   "source": [
    "## Build a detection model and load pre-trained model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rBuD07fLlcEO"
   },
   "outputs": [],
   "source": [
    "print('loading model...')\n",
    "hub_model = hub.load('ALL_MODELS/CenterNet HourGlass104 512x512/1')\n",
    "print('model loaded!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FTHsFjR6HNwb"
   },
   "source": [
    "## Doing the inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gb_siXKcnnGC"
   },
   "outputs": [],
   "source": [
    "parent_dir = r\"test_images/\"\n",
    "image_files = os.listdir(parent_dir)\n",
    "\n",
    "# holds information for cropping\n",
    "image_files_dict = {}\n",
    "\n",
    "# running the detector for each image\n",
    "image_path = \"test_images/1.jpg\" ##[parent_dir+image_files]\n",
    "image_np = load_image_into_numpy_array(image_path)\n",
    "\n",
    "# running inference\n",
    "results = hub_model(image_np)\n",
    "\n",
    "# different object detection models have additional results\n",
    "# all of them are explained in the documentation\n",
    "result = {key:value.numpy() for key,value in results.items()}\n",
    "print(result.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IZ5VYaBoeeFM"
   },
   "source": [
    "## Visualizing the results\n",
    "Here you can, for example, set `min_score_thresh` to other values (between 0 and 1) to allow more detections in or to filter out more detections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2O7rV8g9s8Bz"
   },
   "outputs": [],
   "source": [
    "cars = label_offsets.keys()\n",
    "\n",
    "label_id_offset = 0\n",
    "image_np_with_detections = image_np.copy()\n",
    "\n",
    "# filter cars from all the detections\n",
    "detection_scores = []\n",
    "detection_classes = []\n",
    "detection_boxes = []\n",
    "\n",
    "maximumArea = -1 # biggest bounding box that has car\n",
    "height, width = image_size(image_np)\n",
    "\n",
    "for score, category, boxes in zip(result['detection_scores'][0], (result['detection_classes'][0] + label_id_offset).astype(int), result['detection_boxes'][0]):\n",
    "    if score < 0.9: # only detect cars that have >= 90% certainty\n",
    "        break\n",
    "        \n",
    "    if category not in cars:\n",
    "        continue\n",
    "    \n",
    "    area = area_of_bounding_box(height, width, boxes)\n",
    "    \n",
    "    # if area bigger than current max, replace\n",
    "    if area > maximumArea:\n",
    "        detection_scores = [score]\n",
    "        detection_classes = [category]\n",
    "        detection_boxes = [boxes]\n",
    "\n",
    "detection_scores = np.array(detection_scores)\n",
    "detection_classes = np.array(detection_classes)\n",
    "detection_boxes = np.array(detection_boxes)\n",
    "\n",
    "## visualize the bounding boxes\n",
    "viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "      image_np_with_detections[0],\n",
    "      detection_boxes,\n",
    "      detection_classes,\n",
    "      detection_scores,\n",
    "      category_index,\n",
    "      use_normalized_coordinates=True,\n",
    "      max_boxes_to_draw=200,\n",
    "      min_score_thresh=.30,\n",
    "      agnostic_mode=False,)\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.imshow(image_np_with_detections[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cropping when given the bounding box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Image.open(image_path) as im:\n",
    "    upper, left, lower, right = getCoordingates(height, width, np.squeeze(detection_boxes))\n",
    "    w_ratio = (right-left)/width\n",
    "    h_ratio = (lower-upper)/height\n",
    "\n",
    "    im = im.crop((left, upper, right, lower))\n",
    "    plt.figure(figsize=(15*w_ratio, 10*h_ratio))\n",
    "    plt.imshow(im)\n",
    "    plt.title(label_offsets.get(detection_classes[0], \"no car detected\"))\n",
    "    plt.show()\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Object Detection Inference on TF 2 and TF Hub",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
